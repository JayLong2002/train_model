{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import Accuracy\n",
    "import torch.nn.init as init\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 更改工作目录\n",
    "os.chdir('/home/ubuntu/zlb/MEIJU/train_model')\n",
    "\n",
    "import config as cf\n",
    "\n",
    "# 定义的模型\n",
    "from transformer_model import MultimodalDataset,MultimodalEmotionRecognition,TestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral': 4, 'disgust': 1, 'happy': 3, 'anger': 0, 'sad': 5, 'fear': 2, 'surprise': 6}\n",
      "{4: 'neutral', 1: 'disgust', 3: 'happy', 0: 'anger', 5: 'sad', 2: 'fear', 6: 'surprise'}\n"
     ]
    }
   ],
   "source": [
    "# config.py 里面定义了 emotion2number 和 intent2number ， number2emotion ， number2intent\n",
    "# 这四个映射是为了把intent和emotion 和数字之间相互映射，才能进行学习\n",
    "print(cf.emotion2number)\n",
    "print(cf.number2emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 要加载具体的模型，模型结构上的所有parms都要相同\n",
    "# text_head, text_layers, audio_head , audio_layers , video_head,video_layers\n",
    "# 每次保存模型都会输出parms，直接复制粘贴到这里\n",
    "\n",
    "params = {'audio_head': 16, 'audio_layers': 2, 'batch_size': 32, 'epochs': 5, 'learning_rate': 0.0001, 'text_head': 16, 'text_layers': 2, 'video_head': 16, 'video_layers': 2}\n",
    "model_name =\"10_31_xmodel.pth\"\n",
    "\n",
    "model_save_path = f\"{cf.BEST_MODEL_SAVE_DIR}{model_name}\"\n",
    "\n",
    "TEXT_DIM,AUDIO_DIM,VIDEO_DIM = cf.get_feature_dim()\n",
    "\n",
    "model = MultimodalEmotionRecognition(\n",
    "        text_dim=TEXT_DIM, audio_dim=AUDIO_DIM, video_dim=VIDEO_DIM, \n",
    "        intent_classes=8, emotion_classes=7, \n",
    "        text_head=params['text_head'], text_layers=params['text_layers'],  # 文本 Transformer 参数\n",
    "        audio_head=params['audio_head'], audio_layers=params['audio_layers'],  # 音频 Transformer 参数\n",
    "        video_head=params['video_head'], video_layers=params['video_layers'],  # 视频 Transformer 参数\n",
    ").to(DEVICE)\n",
    "\n",
    "model_dict = torch.load(model_save_path)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /home/ubuntu/zlb/MEIJU/model/save/submission_10.30.csv\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上进行推理, 并且保存结果为submission.csv\n",
    "\n",
    "SAVE_DIR = cf.BEST_MODEL_SAVE_DIR #测试结果保存目录，可以更改，如果不更改，就默认是保存模型的目录\n",
    "result_name = \"submission_10.30.csv\"\n",
    "\n",
    "\n",
    "# -------don't modify----------------\n",
    "\n",
    "test_dataset = TestDataset()\n",
    "test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "all_filename = []\n",
    "emo_pred = []\n",
    "int_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text, audio,video,filename in test_loader:\n",
    "        text,audio,video = text.to(DEVICE),audio.to(DEVICE),video.to(DEVICE)\n",
    "        intent_output, emotion_output = model(text,audio,video)\n",
    "        _, predicted_intent = torch.max(intent_output, 1)\n",
    "        _, predicted_emotion = torch.max(emotion_output, 1)\n",
    "        # 根据映射关系转换为intent和emotion字符串\n",
    "        predicted_intent_str = [cf.number2intent[x.item()] for x in predicted_intent]\n",
    "        predicted_emotion_str = [cf.number2emotion[x.item()] for x in predicted_emotion]\n",
    "        emo_pred.append(predicted_emotion_str)\n",
    "        int_pred.append(predicted_intent_str)\n",
    "        all_filename.append(filename)\n",
    "\n",
    "# 把结果保存为csv\n",
    "emo_pred = np.concatenate(emo_pred)\n",
    "int_pred = np.concatenate(int_pred)\n",
    "all_filename = np.concatenate(all_filename)\n",
    "\n",
    "# 创建DataFrame并保存为CSV文件\n",
    "submission_df = pd.DataFrame({\n",
    "        'filename': all_filename,\n",
    "        'emo_pred': emo_pred,\n",
    "        'int_pred': int_pred\n",
    "})\n",
    "\n",
    "\n",
    "save_dictory = f\"{SAVE_DIR}{result_name}\"\n",
    "\n",
    "submission_df.to_csv(save_dictory, index=False)\n",
    "print(f\"Results saved to {save_dictory}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEIJU",
   "language": "python",
   "name": "meiju"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
